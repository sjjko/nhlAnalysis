{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data mining of NHL data - author: s. konzett-stoffl\\nmethods devised after the book \"Data Mining and Analysis\" by Zakin and Meira\" using nhlscrapi, fetched at http://pythonhosted.org/nhlscrapi\\nand the analysis library scikit learn - the NHL scraper is nhlscrapi, written by Rob Howley - it is distributed under the Apache license - used version in 0.4.3."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook is merely an interface to do the data mining, which stores NHL data files in a folder called datSetsNHL. It imports the setupNhlDataC class to mine data from the NHL data online repositories."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the purpose of analyzing NHL data, I've chosen to read 8 categories out of the NHL teamsummary repository for every game, writing the sum of the categorical data (stored in the file _sum.dat), as well as the difference (in file _delta.dat). The datasets I'm interested in are:\n",
    "\n",
    "Has the home team won?\n",
    "How many goals have been scored?\n",
    "How many shots on goal occured?\n",
    "How many faceoffs have been won by the respective team?\n",
    "How many takeaways have been recorded for the respective team?\n",
    "How many giveaways have been recorded for the respective team?\n",
    "How many penaltyminutes have been recorded for the respective team?\n",
    "How many hits have been recorded for the respective team?\n",
    "How many powerplay goals have been recorded for the respective team?\n",
    "How many people attended the matchups?\n",
    "\n",
    "All these numbers are stored alongside the season, the date of the match relative to the first of october this season, the home team name and finally the guest team name. The first three lines of the 2012 season _sum file look as follows:\n",
    "\n",
    "ID season date T1   T2  WYN GS  SH  FO  TA  GA PIM HITS PPG ATT\n",
    "1   2012    5   BOS PHI 0   3   52  33  10  16  24  36  2   17565\n",
    "2   2012    5   TOR MTL 1   2   50  38  12  22  16  25  0   19606\n",
    "3   2012    5   VAN PIT 0   7   64  51  31  20  12  57  2   18860\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.display import Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data fetching process is quite time-consuming, and so may be done only once. You should find prefetched data in the folder dataSetsNHL. Discussing the Miner class arguments, \"all\" just takes all seasons available in the NHL database, the second boolean argument specifies if the postseason data should be included as well. (which is written into separate files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import setupNhlDataC as setnhl\n",
    "#minerC=setnhl.Miner(\"all\",False)\n",
    "#minerC.mine_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the next step the raw data, fetched using nhlscrapi is turned into something manageable for the data analysis routines. The data, which has been dumped to files, is read and processed into dictionaries, accessible via column names to simplify the data management.\n",
    "\n",
    "We initialize the data preparation class and read NHL data, as well as generate three different sets of artificial game data to compare with the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "from setupNhlDataC import prepareDataC,Miner\n",
    "#read the raw data generated by the miner routine above\n",
    "pDC=prepareDataC(\"all\",readUsingTK=False)\n",
    "#Now we split and recast the dataset! All entries, if feasible, \n",
    "#are converted to numbers. We define a function to streamline the process for all datasets.\n",
    "pDC.prepareData()\n",
    "#data, distributed normal, but independent\n",
    "pDC.generateGenericDataUnCorrelated()\n",
    "#generate uniformly distributed data\n",
    "pDC.generateGenericDataUniform()\n",
    "#now we generate a dictionary with the artificial correlations we want to implement\n",
    "unitCovDict={}\n",
    "unitCovDict[\"ScoreDiff\",\"shotsDiff\"]=0.5\n",
    "unitCovDict[\"FaceoffDiff\",\"GiveawaysDiff\"]=0.7\n",
    "unitCovDict[\"HitsDiff\",\"PenaltyminutesDiff\"]=0.6\n",
    "unitCovDict[\"PenaltyminutesDiff\",\"powerplayGoalsDiff\"]=1\n",
    "#finally generate the season data with the correlations as predetermined\n",
    "pDC.generateGenericDataCorrelated(unitCovDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pminhw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-80e716783d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#compute the statistical moments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmeanhw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpminhw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmeanhl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpminhl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstdhw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpminhw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pminhw' is not defined"
     ]
    }
   ],
   "source": [
    "from ipy_table import *\n",
    "\n",
    "#compute the statistical moments\n",
    "meanhw='{:.2f}'.format(np.mean(pminhw))\n",
    "meanhl='{:.2f}'.format(np.mean(pminhl))\n",
    "stdhw='{:.2f}'.format(np.std(pminhw))\n",
    "stdhl='{:.2f}'.format(np.std(pminhl))\n",
    "skewhw='{:.2f}'.format(stats.skew(pminhw))\n",
    "skewhl='{:.2f}'.format(stats.skew(pminhl))\n",
    "kurthw='{:.2f}'.format(stats.kurtosis(pminhw))\n",
    "kurthl='{:.2f}'.format(stats.kurtosis(pminhl))\n",
    "\n",
    "# lists\n",
    "temp = []\n",
    "dictList = []\n",
    "\n",
    "dictList.append([\"penalty minute statistics\",\"home win\",\"home loss\"])\n",
    "dictList.append([\"mean\",meanhw,meanhl])\n",
    "dictList.append([\"standard deviation\",stdhw,stdhl])\n",
    "dictList.append([\"skewness\",skewhw,skewhl])\n",
    "dictList.append([\"kurtosis\",kurthw,kurthl])\n",
    "\n",
    "# create table with make_table\n",
    "make_table(dictList)\n",
    "\n",
    "# apply some styles to the table after it is created\n",
    "set_row_style(0,bold=True,color='hsla(225,80%,94%,1)')\n",
    "set_column_style(0, width='100', bold=True, color='hsla(225, 80%, 94%, 1)')\n",
    "set_column_style(1, width='100', align='center')\n",
    "set_column_style(2, width='100', align='center')\n",
    "\n",
    "# render the table\n",
    "render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean values indicate a statistical prevalence of higher winning chances for less penalty minutes. The skewness, which marks the asymmetry of the statistics, also sees a trend towards fewer penalty minutes than the opponent if winning. Finally the kurtosis shows a larger spread of data for the lost games, indicating that in games with many penalty minutes losing is more probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latex\n",
    "%%\\phi%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern searching - looking for the most probable configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
