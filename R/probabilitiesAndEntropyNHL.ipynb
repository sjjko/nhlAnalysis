{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We estimate the joint probability function of the dataset and estimate the entropy of various subsets. Additionally we estimate the conditional probability of game success by looking at the various statistics at our disposal. For our purpose we use the package ks (https://cran.r-project.org/web/packages/ks/index.html), which contains density function estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: KernSmooth\n",
      "KernSmooth 2.23 loaded\n",
      "Copyright M. P. Wand 1997-2009\n",
      "Loading required package: misc3d\n",
      "Loading required package: mvtnorm\n",
      "Loading required package: rgl\n"
     ]
    }
   ],
   "source": [
    "library(ks)\n",
    "DATACAPTIONVEC <- c(\"ID\",\"SEASON\",\"DATE\",\"TEAM1\",\"TEAM2\",\"WON\",\"SCORE\",\"SHOTS\",\"FACEOFF\",\"TAKEAWAY\",\"GIVEAWAY\",\"PIM\",\"HITS\",\"PPG\",\"ATTENDANCE\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the first step we read the input data as generated by the python class dataMiner.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nhlDataSum=data.frame()\n",
    "nhlDataDelta=data.frame()\n",
    "SeasonVector=c(2010)#,2011,2012,2014,2015,2016)\n",
    "NumberOfSeasons=length(SeasonVector)\n",
    "for(season in SeasonVector)\n",
    "{\n",
    "  tableName=paste(\"../dataSetsNHL/dataFileNhl_\",season,\"_regular_sum.dat\",sep=\"\")\n",
    "  nhlDataS=read.table(tableName)\n",
    "  colnames(nhlDataS) <- DATACAPTIONVEC\n",
    "  nhlDataSum<-rbind(nhlDataSum,nhlDataS)\n",
    "  tableName=paste(\"../dataSetsNHL/dataFileNhl_\",season,\"_regular_delta.dat\",sep=\"\")\n",
    "  nhlDataS=read.table(tableName)\n",
    "  colnames(nhlDataS) <- DATACAPTIONVEC\n",
    "  nhlDataDelta<-rbind(nhlDataDelta,nhlDataS)\n",
    "}\n",
    "colnames(nhlDataSum) <- DATACAPTIONVEC\n",
    "colnames(nhlDataDelta) <- DATACAPTIONVEC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The raw data of summed and subtracted data for every game is now filtered to break it up into data for every team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"we have the following teams\"\n",
      " [1] BOS       TOR       COL       CGY       CAR       PIT       CHI      \n",
      " [8] DET       BUF       NJ        NYI       NYR       WSH       ATLANTA  \n",
      "[15] FLA       CBJ       DAL       STL       EDM       ANA       LA       \n",
      "[22] VAN       PHI       MIN       TB        NSH       SJ        PHO      \n",
      "[29] CANADIENS OTT      \n",
      "30 Levels: ANA ATLANTA BOS BUF CANADIENS CAR CBJ CGY CHI COL DAL DET ... WSH\n"
     ]
    }
   ],
   "source": [
    "teams <- nhlDataDelta$TEAM1\n",
    "LISTOFTEAMS=unique(teams)\n",
    "print(\"we have the following teams\")\n",
    "print(LISTOFTEAMS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We retrieve data from the summed and the delta dataset, which combined contain the whole game information for every team. In our analysis we look at wins, the difference in shots, difference in faceoffs won, the summed shots and summed faceoffs in the game. To simplify the analysis, we combine the data into one common matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nhlDataMatrix=as.matrix(cbind(nhlDataDelta$WON,nhlDataDelta$SHOTS))#,nhlDataDelta$FACEOFF))#,nhlDataSum$SHOTS,nhlDataSum$FACEOFF))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using this matrix data a joint probability function is estimated, using the kernel estimator function kde from the package ks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.22324\n"
     ]
    }
   ],
   "source": [
    "estimateProbability <- function(inputVector)\n",
    "    {\n",
    "    Pks=kde(nhlDataMatrix,eval.points=inputVector)\n",
    "    return(Pks$estimate)\n",
    "    }\n",
    "#wins,shotsdifference,faceoffdifference,shotssum,faceoffsum\n",
    "iVec=c(1,5)#,5)#,50,40)\n",
    "print(estimateProbability(iVec))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This value is exceedingly small, reflecting the vastness of parameter space. We may now ask the question how probable it is to win, set that the home team has an advantage of more than 10 shots on goal compared to the guest team. To this end we sum up the probability value for all columns and the shot difference column from the maximal value down to 10 shots. I've written a function which calls the ks kde function and sums up probabilites for wins or losses, depending on the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getCondProbability <- function(getWin,PMINV,PMAXV)\n",
    "    {\n",
    "    #function calculating the conditional probability of win or loss given a parameter value for which to calculate the \n",
    "    # probability exceeds the input value\n",
    "    #input:\n",
    "    # getWin - 1 if want to now the probability of winning, else 0 (for loosing)\n",
    "    # parameterSlotIndex - index for the parameter for which to calculate the PDF\n",
    "    # parameterValue - value of the parameter which is assumed to be exceeded\n",
    "    P=0\n",
    "    p1=getWin\n",
    "    p2min=PMINV[2];p3min=PMINV[2];p4min=PMINV[3];p5min=PMINV[4];\n",
    "    p2max=PMAXV[2];p3max=PMAXV[2];p4max=PMAXV[3];p5max=PMAXV[4];\n",
    "    #always integer steps in our statistics\n",
    "        print(P)\n",
    "        for(p2 in p2min:p2max){\n",
    "          #  for(p3 in p3min:p3max){\n",
    "               # for(p4 in p4min:p4max){\n",
    "                   # for(p5 in p5min:p5max)\n",
    "                   #     {\n",
    "                            iVec=c(p1,p2)#,p3,p4,p5)\n",
    "                             #result=kde(nhlDataMatrix,eval.points=iVec)\n",
    "                             #P=P+result$estimate\n",
    "                            P=P+estimateProbability(iVec)\n",
    "                            print(P)\n",
    "                  #  }\n",
    "              #  }\n",
    "           # }\n",
    "        }\n",
    "    print(P)\n",
    "    message=paste(\"We have found a probability of\",P,\" %\")\n",
    "    print(message)\n",
    "    #return(message)\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now let's compute the probability of winning if a team has at least 10 shots more on goal than the opposing team. One could set an additional constraint just by constraining the global variables PMINV,PMAXV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0\n",
      "[1] 0.05386987\n",
      "[1] 0.1186611\n",
      "[1] 0.1974263\n",
      "[1] 0.2926446\n",
      "[1] 0.4054476\n",
      "[1] 0.5352806\n",
      "[1] 0.6800237\n",
      "[1] 0.8365848\n",
      "[1] 1.001971\n",
      "[1] 1.174484\n",
      "[1] 1.354304\n",
      "[1] 1.543027\n",
      "[1] 1.74248\n",
      "[1] 1.953546\n",
      "[1] 2.175523\n",
      "[1] 2.406115\n",
      "[1] 2.641935\n",
      "[1] 2.879234\n",
      "[1] 3.114531\n",
      "[1] 3.344922\n",
      "[1] 3.568163\n",
      "[1] 3.782657\n",
      "[1] 3.98738\n",
      "[1] 4.181667\n",
      "[1] 4.364881\n",
      "[1] 4.536141\n",
      "[1] 4.694265\n",
      "[1] 4.837949\n",
      "[1] 4.966011\n",
      "[1] 5.077635\n",
      "[1] 5.172696\n",
      "[1] 5.172696\n",
      "[1] \"We have found a probability of 5.17269625108125  %\"\n"
     ]
    }
   ],
   "source": [
    "#the third column goes from 10 shots to max value of 30 shots\n",
    "PMINV=c(0,-15,10,30,30)\n",
    "PMAXV=c(1,15,30,50,50)\n",
    "getCondProbability(1,PMINV,PMAXV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
